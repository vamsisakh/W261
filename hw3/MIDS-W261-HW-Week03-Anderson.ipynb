{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## HW3 DATSCI W261 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Names** Safyre Anderson, Howard Wen , Vamsi Sakhamuri\n",
    "\n",
    "**Emails** safyre@berkelye.edu, howard.wen1@gmail.com, vamsi@ischool.berkeley.edu \n",
    "\n",
    "**Time of Initial Submission:** February 4nd, 2016 8am PST\n",
    "\n",
    "**Section** W261-3, Spring 2016  \n",
    "\n",
    "**Week** 3 Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 3.0.\n",
    "*What is a merge sort? Where is it used in Hadoop?*\n",
    "\n",
    "*How is  a combiner function in the context of Hadoop?* \n",
    "\n",
    "*Give an example where it can be used and justify why it should be used in the context of this problem.*\n",
    "\n",
    "*What is the Hadoop shuffle?*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW3.1 Use Counters to do EDA (exploratory data analysis and to monitor progress)\n",
    "*Counters are lightweight objects in Hadoop that allow you to keep track of system progress in both the map and reduce stages of processing. By default, Hadoop defines a number of standard counters in \"groups\"; these show up in the jobtracker webapp, giving you information such as \"Map input records\", \"Map output records\", etc. \n",
    "While processing information/data using MapReduce job, it is a challenge to monitor the progress of parallel threads running across nodes of distributed clusters. Moreover, it is also complicated to distinguish between the data that has been processed and the data which is yet to be processed. The MapReduce Framework offers a provision of user-defined Counters, which can be effectively utilized to monitor the progress of data across nodes of distributed clusters.\n",
    "Use the Consumer Complaints  Dataset provide here to complete this question:*\n",
    "    \n",
    "\n",
    "     https://www.dropbox.com/s/vbalm3yva2rr86m/Consumer_Complaints.csv?dl=0\n",
    "\n",
    "*The consumer complaints dataset consists of diverse consumer complaints, \n",
    "which have been reported across the United States regarding various types of loans. \n",
    "The dataset consists of records of the form:*\n",
    "\n",
    "Complaint ID,Product,Sub-product,Issue,Sub-issue,State,ZIP code,Submitted via,Date received,Date sent to company,Company,Company response,Timely response?,Consumer disputed?\n",
    "\n",
    "*Here’s is the first few lines of the  of the Consumer Complaints  Dataset:*\n",
    "\n",
    "`Complaint ID,Product,Sub-product,Issue,Sub-issue,State,ZIP code,Submitted via,Date received,Date sent to company,Company,Company response,Timely response?,Consumer disputed?\n",
    "1114245,Debt collection,Medical,Disclosure verification of debt,Not given enough info to verify debt,FL,32219,Web,11/13/2014,11/13/2014,\"Choice Recovery, Inc.\",Closed with explanation,Yes,\n",
    "1114488,Debt collection,Medical,Disclosure verification of debt,Right to dispute notice not received,TX,75006,Web,11/13/2014,11/13/2014,\"Expert Global Solutions, Inc.\",In progress,Yes,\n",
    "1114255,Bank account or service,Checking account,Deposits and withdrawals,,NY,11102,Web,11/13/2014,11/13/2014,\"FNIS (Fidelity National Information Services, Inc.)\",In progress,Yes,\n",
    "1115106,Debt collection,\"Other (phone, health club, etc.)\",Communication tactics,Frequent or repeated calls,GA,31721,Web,11/13/2014,11/13/2014,\"Expert Global Solutions, Inc.\",In progress,Yes,`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting yarn daemons\n",
      "starting resourcemanager, logging to /usr/local/hadoop-2.7.1/logs/yarn-Safyre-resourcemanager-Safyres-MacBook-Pro.local.out\n",
      "localhost: starting nodemanager, logging to /usr/local/hadoop-2.7.1/logs/yarn-Safyre-nodemanager-Safyres-MacBook-Pro.local.out\n"
     ]
    }
   ],
   "source": [
    "## First prepare local hadoop cluster in pseudo-distributed mode\n",
    "#!source ~/.bash_profile\n",
    "#!cd $HADOOP_HOME\n",
    "#!$HADOOP_HOME/sbin/start-dfs.sh\n",
    "\n",
    "#!$HADOOP_HOME/bin/hadoop namenode -format\n",
    "!$HADOOP_HOME/sbin/start-yarn.sh\n",
    "#!$HADOOP_HOME/sbin/stop-dfs.sh\n",
    "#!$HADOOP_HOME/sbin/stop-yarn.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3520 SecondaryNameNode\r\n",
      "3314 NameNode\r\n",
      "3779 NodeManager\r\n",
      "3685 ResourceManager\r\n",
      "3404 DataNode\r\n",
      "3820 Jps\r\n"
     ]
    }
   ],
   "source": [
    "# Check PIDS\n",
    "!jps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/30 14:38:43 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 3 items\n",
      "drwx------   - Safyre supergroup          0 2016-01-30 00:13 /tmp\n",
      "drwxr-xr-x   - Safyre supergroup          0 2016-01-30 00:41 /user\n",
      "drwxr-xr-x   - Safyre supergroup          0 2016-01-30 00:36 /usr\n",
      "16/01/30 14:38:44 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 2 items\n",
      "drwxr-xr-x   - Safyre supergroup          0 2016-01-30 14:38 /user/safyre/input\n",
      "drwxr-xr-x   - Safyre supergroup          0 2016-01-30 00:11 /user/safyre/output\n"
     ]
    }
   ],
   "source": [
    "# check dfs\n",
    "!hdfs dfs -ls /\n",
    "!hdfs dfs -ls /user/safyre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-01-30 14:41:04--  https://www.dropbox.com/s/vbalm3yva2rr86m/Consumer_Complaints.csv?dl=0\n",
      "Resolving www.dropbox.com... 108.160.172.206, 108.160.172.238\n",
      "Connecting to www.dropbox.com|108.160.172.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: https://dl.dropboxusercontent.com/content_link/yhmyJdTC9ibqDpuGPBMZV3j9mceF8Dn95CjcDFb4Y141LlH45d1jeU5EoH8kmq31/file [following]\n",
      "--2016-01-30 14:41:05--  https://dl.dropboxusercontent.com/content_link/yhmyJdTC9ibqDpuGPBMZV3j9mceF8Dn95CjcDFb4Y141LlH45d1jeU5EoH8kmq31/file\n",
      "Resolving dl.dropboxusercontent.com... 199.47.217.69\n",
      "Connecting to dl.dropboxusercontent.com|199.47.217.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50906486 (49M) [text/csv]\n",
      "Saving to: '/usr/local/hadoop-2.7.1/input/Consumer_Complaints.csv'\n",
      "\n",
      "/usr/local/hadoop-2 100%[=====================>]  48.55M  3.09MB/s   in 15s    \n",
      "\n",
      "2016-01-30 14:41:23 (3.15 MB/s) - '/usr/local/hadoop-2.7.1/input/Consumer_Complaints.csv' saved [50906486/50906486]\n",
      "\n",
      "16/01/30 14:41:24 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Download assignment data and the \"put\" into hdfs input folder\n",
    "!wget -O $HADOOP_HOME/input/Consumer_Complaints.csv https://www.dropbox.com/s/vbalm3yva2rr86m/Consumer_Complaints.csv?dl=0\n",
    "!hdfs dfs -put $HADOOP_HOME/input/Consumer_Complaints.csv /user/safyre/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 3.1.1  **User-defined Counters**\n",
    "\n",
    "*Now, let’s use Hadoop Counters to identify the number of complaints pertaining to **debt collection, mortgage, and other categories** (all other categories get lumped into this one) in the consumer complaints dataset. Basically produce the distribution of the Product column in this dataset using counters (limited to 3 counters here).*\n",
    "\n",
    "*Hadoop offers Job Tracker, an UI tool to determine the status and statistics of all jobs. Using the job tracker UI, developers can view the Counters that have been created. Screenshot your  job tracker UI as your job completes and include it here. Make sure that your user defined counters are visible.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## reiterate what could be in the data\n",
    "'''Complaint ID,Product,Sub-product,Issue,Sub-issue,State,ZIP code,Submitted via,Date received,Date sent to company,Company,Company response,Timely response?,Consumer disputed?\n",
    "1114245,Debt collection,Medical,Disclosure verification of debt,Not given enough info to verify debt,FL,32219,Web,11/13/2014,11/13/2014,\"Choice Recovery, Inc.\",Closed with explanation,Yes,'''\n",
    "\n",
    "## Looks like we just need to map counts (1's) to each key: Product.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "import sys\n",
    "\n",
    "# delimiter\n",
    "delim = ','\n",
    "\n",
    "for index, line in enumerate(sys.stdin):\n",
    "    \n",
    "    # split by delimiter\n",
    "    sections = line.split(delim)\n",
    "    \n",
    "    # skip the headers and bad rows\n",
    "    if (index == 0) or (len(sections) == 0):\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        # get complaints, each row should be a new complain\n",
    "        PRODUCT = sections[1]\n",
    "        PRODUCT = PRODUCT.lower()\n",
    "        \n",
    "        # collapse exclusive products to 'other'\n",
    "        if PRODUCT not in [\"debt collection\", \"mortgage\"]:\n",
    "            PRODUCT = \"other\"\n",
    "        value = 1\n",
    "        \n",
    "        if PRODUCT == \"debt collection\":\n",
    "            sys.stderr.write(\"reporter:counter:Products,Debt Collection,1\\n\")\n",
    "        elif PRODUCT == \"mortgage\":\n",
    "            sys.stderr.write(\"reporter:counter:Products,Mortgage,1\\n\")\n",
    "        else:\n",
    "            sys.stderr.write(\"reporter:counter:Products,Other,1\\n\")\n",
    "        print \"%s\\t%d\" % (PRODUCT, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "\n",
    "#set up a counts dictionary\n",
    "counts_dict = {}\n",
    "\n",
    "for line in sys.stdin:\n",
    "    key, value = line.split('\\t')\n",
    "    \n",
    "    counts_dict.setdefault(key,0)\n",
    "    counts_dict[key] += int(value)\n",
    "\n",
    "# print out each reduced key value pair\n",
    "\n",
    "for product in counts_dict:\n",
    "    print \"The product \" + product + \" has \" + str(counts_dict[product]) + \" complaints.\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## lazy\n",
    "!chmod a+x *.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## practice run with poor mans' MR\n",
    "!head -n1000 $HADOOP_HOME/input/Consumer_Complaints.csv | ./mapper.py |sort | ./reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting historyserver, logging to /usr/local/hadoop-2.7.1/logs/mapred-Safyre-historyserver-Safyres-MacBook-Pro.local.out\r\n"
     ]
    }
   ],
   "source": [
    "# start the jobtracker server:\n",
    "!$HADOOP_HOME/sbin/mr-jobhistory-daemon.sh --config $HADOOP_HOME/etc/hadoop/ start historyserver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!hdfs dfs -rm -r /user/safyre/output3_1\\n!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar     -file mapper.py     -mapper mapper.py     -file reducer.py     -reducer reducer.py     -input \"/user/safyre/input/Consumer_Complaints.csv\"     -output \"/user/safyre/output3_1\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now with Hadoop Streaming\n",
    "# for some reason hadoop throws an exception because it can't find the \n",
    "###   Error: java.lang.RuntimeException: Error in configuring object\n",
    "###   ... Caused by: java.io.IOException: \n",
    "###   Cannot run program \"reducer.py\": error=2, \n",
    "###   No such file or directory\n",
    "# mapper.py and reducer.py. Added -file arguments for both\n",
    "\n",
    "!hdfs dfs -rm -r /user/safyre/output3_1\n",
    "!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar \\\n",
    "    -file mapper.py \\\n",
    "    -mapper mapper.py \\\n",
    "    -file reducer.py \\\n",
    "    -reducer reducer.py \\\n",
    "    -input \"/user/safyre/input/Consumer_Complaints.csv\" \\\n",
    "    -output \"/user/safyre/output3_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABREAAABKCAYAAAAscxOMAAAKqmlDQ1BJQ0MgUHJvZmlsZQAASImV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\nQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counted 2 map tasks and 1 reduce task. Shouldn't there be one reduce task per key?\n",
    "from IPython.display import Image\n",
    "Image(filename='3_1_counters.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW 3.2 Analyze the performance of your Mappers, Combiners and Reducers using Counters\n",
    "\n",
    "*For this brief study the Input file will be one record (the next line only):*\n",
    "\n",
    "`foo foo quux labs foo bar quux`\n",
    "\n",
    "\n",
    "### 3.2.1 \n",
    "\n",
    "*Perform a word count analysis of this single record dataset using a Mapper and Reducer based WordCount (i.e., no combiners are used here) using user defined Counters to count up how many time the mapper and reducer are called. What is the value of your user defined Mapper Counter, and Reducer Counter after completing this word count job. The answer  should be 1 and 4 respectively. Please explain.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/30 19:34:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "16/01/30 19:34:21 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.\n",
      "Deleted /user/safyre/input/3_2_1.txt\n",
      "16/01/30 19:34:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "16/01/30 19:34:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 2 items\n",
      "-rw-r--r--   1 Safyre supergroup         31 2016-01-30 19:34 /user/safyre/input/3_2_1.txt\n",
      "-rw-r--r--   1 Safyre supergroup   50906486 2016-01-30 14:41 /user/safyre/input/Consumer_Complaints.csv\n"
     ]
    }
   ],
   "source": [
    "## create and insert the one line input file\n",
    "#!echo \"foo foo quux labs foo bar quux\" >> $HADOOP_HOME/input/3_2_1.txt\n",
    "!hdfs dfs -put $HADOOP_HOME/input/3_2_1.txt /user/safyre/input\n",
    "!hdfs dfs -ls /user/safyre/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "#based on lecture code\n",
    "\n",
    "import sys\n",
    "\n",
    "# map count\n",
    "sys.stderr.write(\"reporter:counter:Calls,Num mapper calls,1\\n\")\n",
    "\n",
    "# read in one line\n",
    "for line in sys.stdin:\n",
    "    for token in line.strip().split(\" \"):\n",
    "        if token: # check if token is actually a word and not None\n",
    "            #sys.stderr.write(\"reporter:counter:Words,Total,1\\n\")\n",
    "            print token+\"\\t1\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "# based on lecture code\n",
    "import sys\n",
    "\n",
    "# initialize tuple for reducing\n",
    "(lastKey, sum) = (None, 0)\n",
    "\n",
    "# reduce count\n",
    "sys.stderr.write(\"reporter:counter:Calls,Num reducer calls,1\\n\")\n",
    "\n",
    "# read in one line\n",
    "for line in sys.stdin:\n",
    "    (key, value) =  line.strip().split(\"\\t\")\n",
    "    \n",
    "    ## if we get a new key that is different from the last key (lastKey)\n",
    "    ## print out the sum we've calculated so far for lastKey\n",
    "    ## and start again with key as the new lastKey\n",
    "    if lastKey and lastKey != key:\n",
    "        #sys.stderr.write(\"reporter:counter:Keys,\"+lastKey+\",1\\n\")\n",
    "        print lastKey + \"\\t\" + str(sum)\n",
    "        (lastKey, sum) = (key, int(value))\n",
    "    \n",
    "    ## else, just keep counting\n",
    "    else:\n",
    "        (lastKey, sum) = (key, sum + int(value))\n",
    "\n",
    "## The very last key won't be printed within the for loop\n",
    "## so print it here\n",
    "if lastKey:\n",
    "    #sys.stderr.write(\"reporter:counter:Keys,\"+lastKey+\",1\\n\")\n",
    "    print lastKey + '\\t' + str(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x *.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reporter:counter:Calls,Num mapper calls,1\r\n",
      "reporter:counter:Calls,Num reducer calls,1\r\n",
      "bar\t1\r\n",
      "foo\t3\r\n",
      "labs\t1\r\n",
      "quux\t2\r\n"
     ]
    }
   ],
   "source": [
    "## test with poor man's\n",
    "!cat  $HADOOP_HOME/input/3_2_1.txt | ./mapper.py | sort | ./reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!hdfs dfs -rm -r /user/safyre/output3_2_1\\n!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar     -D mapred.reduce.tasks=4    -file mapper.py     -mapper mapper.py     -file reducer.py     -reducer reducer.py     -input \"/user/safyre/input/3_2_1.txt\"     -output \"/user/safyre/output3_2_1\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## hadoop streaming\n",
    "!hdfs dfs -rm -r /user/safyre/output3_2_1\n",
    "!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar \\\n",
    "    -D mapred.reduce.tasks=4\\\n",
    "    -file mapper.py \\\n",
    "    -mapper mapper.py \\\n",
    "    -file reducer.py \\\n",
    "    -reducer reducer.py \\\n",
    "    -input \"/user/safyre/input/3_2_1.txt\" \\\n",
    "    -output \"/user/safyre/output3_2_1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: Initially with default settings, I was getting 2 mappers and one reducer. It was only after setting the number of reduce tasks to 4 that I got 4 reducers. However, I was still getting two mappers: with only one line per key-value pair and no secondary sorting there should only be one mapper. It's not quite clear to me why the file is still being split to two mappers--it may be a default feature of Hadoop streaming. Additionally, Hadoop should be allocating one key per reducer. Since there are 4 keys in this dataset, I thought Hadoop would automatically spin up a reducer for each key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 \n",
    "\n",
    "*Please use mulitple mappers and reducers for these jobs (at least 2 mappers and 2 reducers).*\n",
    "*Perform a word count analysis of the Issue column of the Consumer Complaints  Dataset using a Mapper and Reducer based WordCount (i.e., no combiners used anywhere)  using user defined Counters to count up how many time the mapper and reducer are called. What is the value of your user defined Mapper Counter, and Reducer Counter after completing your word count job.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "# based on lecture code\n",
    "\n",
    "## Word count in the Issue column, this is the 4th column\n",
    "## or 3rd index\n",
    "\n",
    "import sys\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "delim = \",\"\n",
    "\n",
    "# get a translation table ready to strip punctuation\n",
    "translate_table = string.maketrans(\" \",\" \")\n",
    "\n",
    "# Getting limitexceeded warning. Hoping this will\n",
    "# reduce number of counters\n",
    "stop_list = stopwords.words('english')\n",
    "\n",
    "sys.stderr.write(\"reporter:counter:group,Num mapper calls,1\\n\")\n",
    "for index, line in enumerate(sys.stdin):\n",
    "    \n",
    "    # split by delimiter\n",
    "    sections = line.split(delim)\n",
    "    \n",
    "    # skip the headers and bad rows\n",
    "    if (index == 0) or (len(sections) == 0):\n",
    "        continue\n",
    "    # Grab issue column only\n",
    "    issues = sections[3].lower()\n",
    "    \n",
    "    #strip punctuation\n",
    "    issues = issues.translate(translate_table, string.punctuation)\n",
    "    \n",
    "    for token in issues.strip().split(\" \"):\n",
    "        if token and token not in stop_list: # check if token is actually a word and not None\n",
    "            print token+\"\\t1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "# based on lecture code\n",
    "import sys\n",
    "\n",
    "sys.stderr.write(\"reporter:counter:group,Num reducer calls,1\\n\")\n",
    "# initialize tuple for reducing\n",
    "(lastKey, sum) = (None, 0)\n",
    "\n",
    "# read in one line\n",
    "for line in sys.stdin:\n",
    "    (key, value) =  line.strip().split(\"\\t\")\n",
    "    \n",
    "    ## if we get a new key that is different from the last key (lastKey)\n",
    "    ## print out the sum we've calculated so far for lastKey\n",
    "    ## and start again with key as the new lastKey\n",
    "    if lastKey and lastKey != key:\n",
    "        print lastKey + \"\\t\" + str(sum)\n",
    "        (lastKey, sum) = (key, int(value))\n",
    "    \n",
    "    ## else, just keep counting\n",
    "    else:\n",
    "        (lastKey, sum) = (key, sum + int(value))\n",
    "\n",
    "## The very last key won't be printed within the for loop\n",
    "## so print it here\n",
    "if lastKey:\n",
    "    \n",
    "    print lastKey + '\\t' + str(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!chmod a+x *.py\n",
    "!head -n1000 $HADOOP_HOME/input/Consumer_Complaints.csv |./mapper.py | sort | ./reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/01/30 20:13:30 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 2 items\n",
      "-rw-r--r--   1 Safyre supergroup         31 2016-01-30 19:34 /user/safyre/input/3_2_1.txt\n",
      "-rw-r--r--   1 Safyre supergroup   50906486 2016-01-30 14:41 /user/safyre/input/Consumer_Complaints.csv\n"
     ]
    }
   ],
   "source": [
    "# get input file location again\n",
    "!hdfs dfs -ls /user/safyre/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!hdfs dfs -rm -r /user/safyre/output3_2_2\\n!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar     -D mapreduce.job.maps=2     -D mapreduce.job.reduces=2    -file mapper.py     -file reducer.py     -mapper mapper.py     -reducer reducer.py     -input \"/user/safyre/input/Consumer_Complaints.csv\"     -output \"/user/safyre/output3_2_2\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## hadoop streaming\n",
    "## Kept getting memory erros, need to increase block size!\n",
    "## also got this interesting error from job's syslog file in chunk 02\n",
    "## in $HADOOP_HOME/logs/userlogs/application_1454192816461_0024/container_1454192816461_0024_01_000002\n",
    "## \"rg.apache.hadoop.streaming.PipeMapRed: \n",
    "##    org.apache.hadoop.mapreduce.counters.LimitExceededException: Too many counters: 121 max=120\"\n",
    "\n",
    "## SOLUTION: set the mapreduce.job.counters.max = 300 (was getting 169 counters)\n",
    "\n",
    "!hdfs dfs -rm -r /user/safyre/output3_2_2\n",
    "!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar \\\n",
    "    -D mapreduce.job.maps=2 \\\n",
    "    -D mapreduce.job.reduces=2\\\n",
    "    -file mapper.py \\\n",
    "    -file reducer.py \\\n",
    "    -mapper mapper.py \\\n",
    "    -reducer reducer.py \\\n",
    "    -input \"/user/safyre/input/Consumer_Complaints.csv\" \\\n",
    "    -output \"/user/safyre/output3_2_2\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/safyre/output3_2_2/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 \n",
    "\n",
    "*Perform a word count analysis of the Issue column of the Consumer Complaints  Dataset using a Mapper, Reducer, and standalone combiner (i.e., not an in-memory combiner) based WordCount using user defined Counters to count up how many time the mapper, combiner, reducer are called. What is the value of your user defined Mapper Counter, and Reducer Counter after completing your word count job.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting combiner.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile combiner.py\n",
    "#!/usr/bin/env python\n",
    "# Combiner, combining counts\n",
    "# sums are associative and commutative\n",
    "# a combiner can take advantage of these properties\n",
    "# to try to achieve some performance gains--i.e. fewer spillovers\n",
    "import sys\n",
    "\n",
    "sys.stderr.write(\"reporter:counter:group,Num combiner calls,1\\n\")\n",
    "# initialize tuple for reducing\n",
    "(lastKey, sum) = (None, 0)\n",
    "\n",
    "# read in one line\n",
    "for line in sys.stdin:\n",
    "    (key, value) =  line.strip().split(\"\\t\")\n",
    "    \n",
    "    ## if we get a new key that is different from the last key (lastKey)\n",
    "    ## print out the sum we've calculated so far for lastKey\n",
    "    ## and start again with key as the new lastKey\n",
    "    if lastKey and lastKey != key:\n",
    "        print lastKey + \"\\t\" + str(sum)\n",
    "        (lastKey, sum) = (key, int(value))\n",
    "    \n",
    "    ## else, just keep counting\n",
    "    else:\n",
    "        (lastKey, sum) = (key, sum + int(value))\n",
    "\n",
    "## The very last key won't be printed within the for loop\n",
    "## so print it here\n",
    "if lastKey:\n",
    "    \n",
    "    print lastKey + '\\t' + str(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x *.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!hdfs dfs -rm -r /user/safyre/output3_2_3\\n!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar     -D mapreduce.job.maps=2     -D mapreduce.job.reduces=2    -file mapper.py     -file reducer.py     -file combiner.py     -mapper mapper.py     -reducer reducer.py     -combiner combiner.py     -input \"/user/safyre/input/Consumer_Complaints.csv\"     -output \"/user/safyre/output3_2_3\"'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## redo with a combiner\n",
    "!hdfs dfs -rm -r /user/safyre/output3_2_3\n",
    "!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar \\\n",
    "    -D mapreduce.job.maps=2 \\\n",
    "    -D mapreduce.job.reduces=2\\\n",
    "    -file mapper.py \\\n",
    "    -file reducer.py \\\n",
    "    -file combiner.py \\\n",
    "    -mapper mapper.py \\\n",
    "    -reducer reducer.py \\\n",
    "    -combiner combiner.py \\\n",
    "    -input \"/user/safyre/input/Consumer_Complaints.csv\" \\\n",
    "    -output \"/user/safyre/output3_2_3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** The mapper, combiner, and reducer were called 4, 2, and 2 times respectively. Adding the combiner improved the the GC (garbage collection) time by 24 ms, reduced the records load on the mapper and reducer tasks, and reduced spillover from 1,606,924 records to 534 records. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 \n",
    "\n",
    "*Using a single reducer: What are the top 50 most frequent terms in your word count analysis? Present the top 50 terms and their frequency and their relative frequency. If there are ties please sort the tokens in alphanumeric/string order. Present bottom 10 tokens (least frequent items).* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile combiner.py\n",
    "#!/usr/bin/env python\n",
    "# Combiner, combining counts\n",
    "# sums are associative and commutative\n",
    "# a combiner can take advantage of these properties\n",
    "# to try to achieve some performance gains--i.e. fewer spillovers\n",
    "import sys\n",
    "\n",
    "sys.stderr.write(\"reporter:counter:group,Num combiner calls,1\\n\")\n",
    "# initialize tuple for reducing\n",
    "(lastKey, sum) = (None, 0)\n",
    "\n",
    "# also output the overall sum for relative frequencies\n",
    "total_count = 0\n",
    "\n",
    "# read in one line\n",
    "for line in sys.stdin:\n",
    "    (key, value) =  line.strip().split(\"\\t\")\n",
    "    \n",
    "    ## if we get a new key that is different from the last key (lastKey)\n",
    "    ## print out the sum we've calculated so far for lastKey\n",
    "    ## and start again with key as the new lastKey\n",
    "    ### for this part, reverse the key and values to sort by frequencies\n",
    "    if lastKey and lastKey != key:\n",
    "        print  lastKey + \"\\t\" + str(sum)\n",
    "        (lastKey, sum) = (key, int(value))\n",
    "    \n",
    "    ## else, just keep counting\n",
    "    else:\n",
    "        (lastKey, sum) = (key, sum + int(value))\n",
    "        total_count += int(value)\n",
    "\n",
    "## The very last key won't be printed within the for loop\n",
    "## so print it here\n",
    "if lastKey:\n",
    "    print lastKey + \"\\t\" + str(sum) \n",
    "    \n",
    "## Finally, print the count of all words\n",
    "print  \"*\" + \"\\t\" + str(total_count) #+ str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "# based on solutions from homework 2\n",
    "\n",
    "## However, the idea here is the keys are now the words,\n",
    "# but we are sorting by value (sum)\n",
    "\n",
    "import sys, Queue\n",
    "\n",
    "# set number of top and bottom frequencies\n",
    "n_max, n_min = 50, 10\n",
    "q_max = Queue.Queue(n_max)\n",
    "a_min = []\n",
    "total_count = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "    rec = line.split('\\t')\n",
    "    rec[1] =rec[1].strip()\n",
    "    \n",
    "    # grab the total counts to get relative frequencies\n",
    "    if rec[0] == \"*\":\n",
    "        total_count = int(rec[1])\n",
    "        continue\n",
    "    \n",
    "    # put the smallest values into the list until\n",
    "    # the list size = 10\n",
    "    if len(a_min) < n_min:\n",
    "        a_min.append('\\t'.join(rec))\n",
    "        \n",
    "    \n",
    "    # once the queue is full (50 items)\n",
    "    # remove and return the values\n",
    "    if q_max.full():\n",
    "        q_max.get()\n",
    "        \n",
    "    # put the remainders into the queue as lists\n",
    "    q_max.put('\\t'.join(rec))\n",
    "\n",
    "print '\\n%d smallest records:' %n_min\n",
    "for record in a_min:\n",
    "    print record\n",
    "\n",
    "print '\\n%d biggest records:' %n_max\n",
    "for i in range(n_max):\n",
    "    print q_max.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer2.py\n",
    "#!/usr/bin/python\n",
    "# Rewriting the reducer to try and combine the counts\n",
    "\n",
    "## However, the idea here is the keys are now the words,\n",
    "# but we are sorting by value (sum)\n",
    "\n",
    "import sys, Queue\n",
    "\n",
    "# initialize tuple for reducing\n",
    "[lastKey, keysum] = [None, 0]\n",
    "\n",
    "# also output the overall sum for relative frequencies\n",
    "total_count = 0\n",
    "all_kv = []\n",
    "\n",
    "# read in one line\n",
    "for line in sys.stdin:\n",
    "    [key, value] =  line.strip().split(\"\\t\")\n",
    "    \n",
    "    ## if we get a new key that is different from the last key (lastKey)\n",
    "    ## print out the sum we've calculated so far for lastKey\n",
    "    ## and start again with key as the new lastKey\n",
    "    ### for this part, reverse the key and values to sort by frequencies\n",
    "    if lastKey and lastKey != key:\n",
    "        [lastKey, keysum] = [key, int(value)]\n",
    "        all_kv.append([lastKey, str(keysum)])\n",
    "        total_count += keysum\n",
    "        \n",
    "    ## else, just keep counting\n",
    "    else:\n",
    "        [lastKey, keysum] = [key, keysum + int(value)]\n",
    "\n",
    "## Finally, print the count of all words\n",
    "all_kv.append([\"*\", str(total_count)])\n",
    "\n",
    "\n",
    "## now grab top 50 and bottom 10\n",
    "# set number of top and bottom frequencies\n",
    "n_max, n_min = 50, 10\n",
    "q_max = Queue.Queue(n_max)\n",
    "a_min = []\n",
    "\n",
    "for rec in all_kv:  \n",
    "    # grab the total counts to get relative frequencies\n",
    "    if rec[0] == \"*\":\n",
    "        total_count = int(rec[1])\n",
    "        continue\n",
    "    \n",
    "    # put the smallest values into the list until\n",
    "    # the list size = 10\n",
    "    if len(a_min) < n_min:\n",
    "        a_min.append('\\t'.join(rec))\n",
    "        \n",
    "    \n",
    "    # once the queue is full (50 items)\n",
    "    # remove and return the values\n",
    "    if q_max.full():\n",
    "        q_max.get()\n",
    "        \n",
    "    # put the remainders into the queue as lists\n",
    "    q_max.put('\\t'.join(rec))\n",
    "\n",
    "print '\\n%d smallest records:' %n_min\n",
    "for record in a_min:\n",
    "    print record\n",
    "\n",
    "print '\\n%d biggest records:' %n_max\n",
    "for i in range(n_max):\n",
    "    print q_max.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x *.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## poor mans version\n",
    "# k 2,2 means sort on second field only\n",
    "# rn means reverse (desc) numeric sort\n",
    "!head -n1000 $HADOOP_HOME/input/Consumer_Complaints.csv |./mapper.py |sort |./combiner.py|sort -k2,2n -k1,1 | ./reducer2.py #|head -n50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!hdfs dfs -rm -r /user/safyre/output3_2_4\\n!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar     -D stream.num.map.output.key.fields=2    -D mapreduce.job.maps=1     -D mapreduce.job.reduces=1    -file mapper.py     -file reducer2.py     -file combiner.py     -mapper mapper.py     -combiner combiner.py     -reducer reducer2.py     -input \"/user/safyre/input/Consumer_Complaints.csv\"     -output \"/user/safyre/output3_2_4\"\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## redo with a combiner\n",
    "## Some notes on the mapred parameters\n",
    "#    stream.num.map.output.key.fields=2, tells hadoop both fields (we only have two) should be treated like keys\n",
    "# -D mapreduce.partition.keypartitioner.options=\"-k2,2\" \\\n",
    "# -D mapreduce.partition.keycomparator.options=\"-k2,2n -k1,1\" \\\n",
    "#    -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \\\n",
    "#    -D mapreduce.map.output.key.field.separator='\\t' \\\n",
    "\n",
    "!hdfs dfs -rm -r /user/safyre/output3_2_4\n",
    "!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar \\\n",
    "    -D stream.num.map.output.key.fields=2\\\n",
    "    -D mapreduce.job.maps=1 \\\n",
    "    -D mapreduce.job.reduces=1\\\n",
    "    -file mapper.py \\\n",
    "    -file reducer2.py \\\n",
    "    -file combiner.py \\\n",
    "    -mapper mapper.py \\\n",
    "    -combiner combiner.py \\\n",
    "    -reducer reducer2.py \\\n",
    "    -input \"/user/safyre/input/Consumer_Complaints.csv\" \\\n",
    "    -output \"/user/safyre/output3_2_4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check output\n",
    "!hdfs dfs -ls /user/safyre/output3_2_4\n",
    "###   Found 3 items\n",
    "###   -rw-r--r--   1 Safyre supergroup        /user/safyre/output3_2_4/_SUCCESS\n",
    "###   -rw-r--r--   1 Safyre supergroup       /user/safyre/output3_2_4/part-00000\n",
    "\n",
    "!hdfs dfs -cat /user/safyre/output3_2_4/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 OPTIONAL \n",
    "*Using 2 reducers: What are the top 50 most frequent terms in your word count analysis? Present the top 50 terms and their frequency and their relative frequency. Present the top 50 terms and their frequency and their relative frequency. If there are ties please sort the tokens in alphanumeric/string order. Present bottom 10 tokens (least frequent items). Please use a combiner.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW3.3. Shopping Cart Analysis\n",
    "*Product Recommendations: The action or practice of selling additional products or services \n",
    "to existing customers is called cross-selling. Giving product recommendation is \n",
    "one of the examples of cross-selling that are frequently used by online retailers. \n",
    "One simple method to give product recommendations is to recommend products that are frequently\n",
    "browsed together by the customers.*\n",
    "\n",
    "*For this homework use the online browsing behavior dataset located at:* \n",
    "\n",
    "       https://www.dropbox.com/s/zlfyiwa70poqg74/ProductPurchaseData.txt?dl=0\n",
    "\n",
    "*Each line in this dataset represents a browsing session of a customer. \n",
    "On each line, each string of 8 characters represents the id of an item browsed during that session. \n",
    "The items are separated by spaces.*\n",
    "\n",
    "*Here are the first few lines of the ProductPurchaseData* \n",
    "\n",
    "`FRO11987 ELE17451 ELE89019 SNA90258 GRO99222 \n",
    "GRO99222 GRO12298 FRO12685 ELE91550 SNA11465 ELE26917 ELE52966 FRO90334 SNA30755 ELE17451 FRO84225 SNA80192 \n",
    "ELE17451 GRO73461 DAI22896 SNA99873 FRO86643 \n",
    "ELE17451 ELE37798 FRO86643 GRO56989 ELE23393 SNA11465 \n",
    "ELE17451 SNA69641 FRO86643 FRO78087 SNA11465 GRO39357 ELE28573 ELE11375 DAI54444` \n",
    "\n",
    "\n",
    "**Do some exploratory data analysis of this dataset.** \n",
    "\n",
    "*How many unique items are available from this supplier?*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the data\n",
    "!wget -O $HADOOP_HOME/input/ProductPurchaseData.txt https://www.dropbox.com/s/zlfyiwa70poqg74/ProductPurchaseData.txt?dl=\n",
    "!hdfs dfs -put $HADOOP_HOME/input/ProductPurchaseData.txt /user/safyre/input\n",
    "!hdfs dfs -ls /user/safyre/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "# based on lecture code\n",
    "\n",
    "## Word count in the Issue column, this is the 4th column\n",
    "## or 3rd index\n",
    "\n",
    "import sys\n",
    "delim = \" \"\n",
    "\n",
    "sys.stderr.write(\"reporter:counter:group,Num mapper calls,1\\n\")\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    # split by delimiter\n",
    "    items = line.strip().split(delim)\n",
    "    \n",
    "    # skip bad rows\n",
    "    if (len(sections) == 0):\n",
    "        continue\n",
    "    \n",
    "    for item in items:\n",
    "        print token+\"\\t1\" +str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "# based on lecture code\n",
    "import sys\n",
    "\n",
    "sys.stderr.write(\"reporter:counter:group,Num reducer calls,1\\n\")\n",
    "# initialize tuple for reducing\n",
    "(lastKey, sum) = (None, 0)\n",
    "\n",
    "# read in one line\n",
    "for line in sys.stdin:\n",
    "    (key, value) =  line.strip().split(\"\\t\")\n",
    "    \n",
    "    ## if we get a new key that is different from the last key (lastKey)\n",
    "    ## print out the sum we've calculated so far for lastKey\n",
    "    ## and start again with key as the new lastKey\n",
    "    if lastKey and lastKey != key:\n",
    "        print lastKey + \"\\t\" + str(sum)\n",
    "        (lastKey, sum) = (key, int(value))\n",
    "    \n",
    "    ## else, just keep counting\n",
    "    else:\n",
    "        (lastKey, sum) = (key, sum + int(value))\n",
    "\n",
    "## The very last key won't be printed within the for loop\n",
    "## so print it here\n",
    "if lastKey:\n",
    "    print lastKey + '\\t' + str(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chmod a+x *.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using a single reducer: Report your findings such as number of unique products; largest basket; report the top 50 most frequently purchased items,  their frequency,  and their relative frequency (break ties by sorting the products alphabetical order) etc. using Hadoop Map-Reduce.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 OPTIONAL \n",
    "Using 2 reducers:  Report your findings such as number of unique products; largest basket; report the top 50 most frequently purchased items,  their frequency,  and their relative frequency (break ties by sorting the products alphabetical order) etc. using Hadoop Map-Reduce. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW3.4. (Computationally prohibitive but then again Hadoop can handle this) Pairs\n",
    "\n",
    "*Suppose we want to recommend new products to the customer based on the products they\n",
    "have already browsed on the online website. Write a map-reduce program \n",
    "to find products which are frequently browsed together. Fix the support count (cooccurence count) to s = 100 \n",
    "(i.e. product pairs need to occur together at least 100 times to be considered frequent) \n",
    "and find pairs of items (sometimes referred to itemsets of size 2 in association rule mining) that have a support count of 100 or more.*\n",
    "\n",
    "*List the top 50 product pairs with corresponding support count (aka frequency), and relative frequency or support ( the number of records where they coccur/the number of baskets in the dataset)  in decreasing order of support  for frequent (100>count) itemsets of size 2.* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "# based on lecture code\n",
    "\n",
    "## Word count in the Issue column, this is the 4th column\n",
    "## or 3rd index\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import Counter #easy to count pairs\n",
    "\n",
    "delim = \" \"\n",
    "\n",
    "sys.stderr.write(\"reporter:counter:group,Num mapper calls,1\\n\")\n",
    "for line in sys.stdin:\n",
    "    # split by delimiter\n",
    "    items = line.strip().split(delim)\n",
    "    \n",
    "    # skip bad rows\n",
    "    if (len(items) == 0):\n",
    "        continue\n",
    "    \n",
    "    #pairs = Counter(zip(items, items[1:]))\n",
    "    \n",
    "    #pairs = {}\n",
    "    #for item1 in items[:-1]:\n",
    "    #    for item2 in items[1::]:\n",
    "    #        pairs[item1 + \" \" +item2] = str(1)\n",
    "\n",
    "            \n",
    "            \n",
    "    for item1 in items:\n",
    "        for item2 in items[1::]:\n",
    "    #for pair in pairs:    \n",
    "        # some sorting by whichever item is greater lexicographically\n",
    "            if item1 < item2:\n",
    "                #print \"%s\\t%s\\t%s\" % (pair[0], pair[1], pairs[pair])\n",
    "                print \"%s\\t%s\\t%s\" % (item1, item2, str(1))\n",
    "\n",
    "                # print for order inversion\n",
    "                #print \"%s\\t*\\t%s\"  % (pair[0], str(1))\n",
    "                print \"%s\\t*\\t%s\"  % (item1, str(1))\n",
    "            else:\n",
    "                #print \"%s\\t%s\\t%s\" % (pair[1], pair[0], pairs[pair])\n",
    "                print \"%s\\t%s\\t%s\" % (item1, item2, str(1))\n",
    "\n",
    "                # print for order inversion\n",
    "                #print \"%s\\t*\\t%s\"  % (pair[1], str(1))\n",
    "                print \"%s\\t*\\t%s\"  % (item1, str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "# based on lecture code\n",
    "import sys\n",
    "\n",
    "sys.stderr.write(\"reporter:counter:group,Num reducer calls,1\\n\")\n",
    "# initialize tuple for reducing\n",
    "(lastKey, sum) = (None, 0)\n",
    "\n",
    "# read in one line\n",
    "for line in sys.stdin:\n",
    "    key1, key2, count=  line.strip().split(\"\\t\")\n",
    "    \n",
    "    # glue the keys back together\n",
    "    (key, value) = key1 + \"\\t\" + key2, count\n",
    "    \n",
    "    ## if we get a new key that is different from the last key (lastKey)\n",
    "    ## print out the sum we've calculated so far for lastKey\n",
    "    ## and start again with key as the new lastKey\n",
    "    if lastKey and lastKey != key:\n",
    "\n",
    "        if lastKey.split(\"\\t\")[1] == \"*\":\n",
    "            nkey1 = sum\n",
    "            #print lastKey + \"\\t\" + str(sum)\n",
    "            \n",
    "        elif nkey1:\n",
    "            freq = float(sum)/nkey1\n",
    "            if sum >=100:\n",
    "                print lastKey + \"\\t\" + str(sum) + \"\\t\" + str(freq)\n",
    "        \n",
    "        (lastKey, sum) = (key, int(value))\n",
    "    \n",
    "    ## else, just keep counting\n",
    "    else:\n",
    "        (lastKey, sum) = (key, sum + int(value))\n",
    "\n",
    "## The very last key won't be printed within the for loop\n",
    "## so print it here\n",
    "if lastKey and lastKey.split(\"\\t\")[1] != \"*\":\n",
    "    freq = float(sum)/nkey1\n",
    "    \n",
    "    if sum >= 100:\n",
    "        print lastKey + '\\t' + str(sum) + \"\\t\" + str(freq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer2.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys, Queue\n",
    "\n",
    "\n",
    "'''class Stack:\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "\n",
    "    def isEmpty(self):\n",
    "        return self.items == []\n",
    "\n",
    "    def push(self, item):\n",
    "        self.items.append(item)\n",
    "\n",
    "    def pop(self):\n",
    "        return self.items.pop()\n",
    "\n",
    "    def peek(self):\n",
    "        return self.items[len(self.items)-1]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.items)'''\n",
    "\n",
    "        \n",
    "n_max = 50\n",
    "q_max = Queue.Queue(n_max)\n",
    "\n",
    "\n",
    "for pair in sys.stdin:  \n",
    "    # grab the total counts to get relative frequencies\n",
    "    rec = pair.split('-')\n",
    "    \n",
    "    # once the queue is full (50 items)\n",
    "    # remove and return the values\n",
    "    if q_max.full():\n",
    "        q_max.get()\n",
    "        \n",
    "    # put the remainders into the queue as lists\n",
    "    q_max.put('\\t'.join(rec))\n",
    "\n",
    "print '\\n%d biggest records:' %n_max\n",
    "\n",
    "\n",
    "    \n",
    "'''## need to reprint in reverse,\n",
    "## numbers are top 50 in ascending order\n",
    "## offload the queue into a stack and then\n",
    "## pop the values off the top of the stack\n",
    "## until it's empty\n",
    "aux_stack = Stack()\n",
    "while not aux_stack.isEmpty():\n",
    "    aux_stack.push(q_max.dequeue())\n",
    "\n",
    "while not aux_stack.isEmpty():\n",
    "    q_max.enqueue(aux_stack.pop())'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# will hang otherwise if Queue isn't filled\n",
    "for i in range(n_max):\n",
    "    try:\n",
    "        task = q_max.get(timeout=1) #timeout throws and Empty exception\n",
    "        print q_max.get()\n",
    "\n",
    "    except Queue.Empty:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!chmod a+x *.py\n",
    "!head -n5000 $HADOOP_HOME/input/ProductPurchaseData.txt | ./mapper.py |sort | ./reducer.py #| sort -k3,3rn | ./reducer2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "16/02/03 22:56:12 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "16/02/03 22:56:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "packageJobJar: [mapper.py, reducer.py, reducer2.py, /var/folders/jz/dhc2gzfj2091nhfmrbvv3cjh0000gn/T/hadoop-unjar1834670952883990278/] [] /var/folders/jz/dhc2gzfj2091nhfmrbvv3cjh0000gn/T/streamjob7822266202527297471.jar tmpDir=null\n",
      "16/02/03 22:56:14 INFO client.RMProxy: Connecting to ResourceManager at /127.0.0.1:8032\n",
      "16/02/03 22:56:14 INFO client.RMProxy: Connecting to ResourceManager at /127.0.0.1:8032\n",
      "16/02/03 22:56:14 ERROR streaming.StreamJob: Error Launching job : Call From safyres-macbook-pro.local/10.1.10.136 to localhost:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused\n",
      "Streaming Command Failed!\n"
     ]
    }
   ],
   "source": [
    "## redo with a combiner\n",
    "#Some notes on the mapred parameters\n",
    "#    stream.num.map.output.key.fields=2, tells hadoop both fields (we only have two) should be treated like keys\n",
    "# -D mapreduce.partition.keypartitioner.options=\"-k2,2\" \\\n",
    "# -D mapreduce.partition.keycomparator.options=\"-k2,2n -k1,1\" \\\n",
    "#    -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \\\n",
    "#    -D mapreduce.map.output.key.field.separator='\\t' \\\n",
    "!hdfs dfs -rm -r /user/safyre/output3_4\n",
    "!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar \\\n",
    "    -D stream.num.map.output.key.fields=3 \\\n",
    "    -D mapreduce.map.output.key.field.separator='\\t' \\\n",
    "    -D mapreduce.partition.keypartitioner.options=\"-k1,1\" \\\n",
    "    -file mapper.py \\\n",
    "    -file reducer.py \\\n",
    "    -file reducer2.py \\\n",
    "    -mapper mapper.py \\\n",
    "    -input \"/user/safyre/input/ProductPurchaseData.txt\" \\\n",
    "    -output \"/user/safyre/output3_4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/safyre/output3_4/part-00000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mappersort.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mappersort.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "## a mapper used to just sort the data\n",
    "\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line = line.strip()\n",
    "    \n",
    "    # wondering if the sorter can't detect a \\t character\n",
    "    line = \"-\".join(line.split())\n",
    "    print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod a+x *.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!hdfs dfs -rm -r /user/safyre/output3_4_2\\n!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar     -D stream.num.map.output.key.fields=3     -D mapreduce.partition.keycomparator.options=\"-k3,3n -k1,1\"     -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator     -D mapreduce.map.output.key.field.separator=\"-\"     -file mapper.py     -file reducer.py     -file reducer2.py     -file mappersort.py     -mapper mappersort.py     -reducer reducer2.py     -input \"/user/safyre/output3_4/part-00000\"     -output \"/user/safyre/output3_4_2\"\\n    '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!hdfs dfs -ls /user/safyre/output3_4\n",
    "#!hdfs dfs -cat /user/safyre/output3_4/part-00000\n",
    "\n",
    "## Part 2!\n",
    "\n",
    "!hdfs dfs -rm -r /user/safyre/output3_4_2\n",
    "!hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-2*.jar \\\n",
    "    -D stream.num.map.output.key.fields=3 \\\n",
    "    -D mapreduce.partition.keycomparator.options=\"-k3,3n -k1,1\" \\\n",
    "    -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \\\n",
    "    -D mapreduce.map.output.key.field.separator=\"-\" \\\n",
    "    -file mapper.py \\\n",
    "    -file reducer.py \\\n",
    "    -file reducer2.py \\\n",
    "    -file mappersort.py \\\n",
    "    -mapper mappersort.py \\\n",
    "    -reducer reducer2.py \\\n",
    "    -input \"/user/safyre/output3_4/part-00000\" \\\n",
    "    -output \"/user/safyre/output3_4_2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/02/03 21:40:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Found 2 items\n",
      "-rw-r--r--   1 Safyre supergroup          0 2016-02-03 21:40 /user/safyre/output3_4_2/_SUCCESS\n",
      "-rw-r--r--   1 Safyre supergroup        222 2016-02-03 21:40 /user/safyre/output3_4_2/part-00000\n",
      "16/02/03 21:40:20 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "\t\n",
      "50 biggest records:\t\n",
      "F\tR\t76539\t1.0\t\n",
      "\t\n",
      "A\tD\t88004\t1.0\t\n",
      "\t\n",
      "F\tR\t121935\t0.999991798977\t\n",
      "\t\n",
      "G\tR\t127495\t1.0\t\n",
      "\t\n",
      "E\tL\t143387\t1.0\t\n",
      "\t\n",
      "F\tR\t327806\t1.00000305059\t\n",
      "\t\n",
      "N\tS\t344997\t1.0\t\n",
      "\t\n",
      "G\tR\t382135\t1.0\t\n",
      "\t\n",
      "E\tL\t388537\t1.0\t\n",
      "\t\n",
      "E\tL\t404824\t1.0\t\n",
      "\t\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/safyre/output3_4_2\n",
    "!hdfs dfs -cat /user/safyre/output3_4_2/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Use the Pairs pattern (lecture 3)  to  extract these frequent itemsets of size 2. Free free to use combiners if they bring value. Instrument your code with counters for count the number of times your mapper, combiner and reducers are called.*  \n",
    "\n",
    "*Please output records of the following form for the top 50 pairs (itemsets of size 2):* \n",
    "\n",
    "      item1, item2, support count, support\n",
    "\n",
    "\n",
    "\n",
    "*Fix the ordering of the pairs lexicographically (left to right), \n",
    "and break ties in support (between pairs, if any exist) \n",
    "by taking the first ones in lexicographically increasing order.* \n",
    "\n",
    "*Report  the compute time for the Pairs job. Describe the computational setup used (E.g., single computer; dual core; linux, number of mappers, number of reducers)\n",
    "Instrument your mapper, combiner, and reducer to count how many times each is called using Counters and report these counts.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### HW3.5: Stripes\n",
    "*Repeat 3.4 using the stripes design pattern for finding cooccuring pairs.*\n",
    "\n",
    "*Report  the compute times for stripes job versus the Pairs job. Describe the computational setup used (E.g., single computer; dual core; linux, number of mappers, number of reducers)*\n",
    "\n",
    "*Instrument your mapper, combiner, and reducer to count how many times each is called using Counters and report these counts. Discuss the differences in these counts between the Pairs and Stripes jobs*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "OPTIONAL: all HW below this are optional \n",
    "\n",
    "NOTE:   -- as of 1/28/2016 the instructions needs to be completed (Talk to Jimi)\n",
    "\n",
    "\n",
    "\n",
    "== Preliminary information ===\n",
    "\n",
    "Much of this homework beyond this point will focus on the Apriori algorithm for frequent itemset  mining and the additional step for extracting association rules from these frequent itemsets.\n",
    "Please acquaint yourself with the background information (below)\n",
    "before approaching the remaining  assignments.\n",
    "\n",
    "=== Apriori background information ===\n",
    "\n",
    "Some background material for the  Apriori algorithm is located at:\n",
    "\n",
    " - Slides in Live Session #3\n",
    " - https://en.wikipedia.org/wiki/Apriori_algorithm\n",
    " - https://www.dropbox.com/s/k2zm4otych279z2/Apriori-good-slides.pdf?dl=0\n",
    " - http://snap.stanford.edu/class/cs246-2014/slides/02-assocrules.pdf\n",
    "\n",
    "Association Rules are frequently used for Market Basket Analysis (MBA) by retailers to\n",
    "understand the purchase behavior of their customers. This information can be then used for\n",
    "many different purposes such as cross-selling and up-selling of products, sales promotions,\n",
    "loyalty programs, store design, discount plans and many others.\n",
    "Evaluation of item sets: Once you have found the frequent itemsets of a dataset, you need\n",
    "to choose a subset of them as your recommendations. Commonly used metrics for measuring\n",
    "significance and interest for selecting rules for recommendations are: confidence; lift; and conviction.\n",
    "\n",
    "HW3.6\n",
    "What is the Apriori algorithm? Describe an example use in your domain of expertise and what kind of . Define confidence and lift.\n",
    "\n",
    "NOTE:\n",
    "For the remaining homework use the online browsing behavior dataset located at (same dataset as used above): \n",
    "\n",
    "       https://www.dropbox.com/s/zlfyiwa70poqg74/ProductPurchaseData.txt?dl=0\n",
    "\n",
    "Each line in this dataset represents a browsing session of a customer. \n",
    "On each line, each string of 8 characters represents the id of an item browsed during that session. \n",
    "The items are separated by spaces.\n",
    "\n",
    "Here are the first few lines of the ProductPurchaseData \n",
    "FRO11987 ELE17451 ELE89019 SNA90258 GRO99222 \n",
    "GRO99222 GRO12298 FRO12685 ELE91550 SNA11465 ELE26917 ELE52966 FRO90334 SNA30755 ELE17451 FRO84225 SNA80192 \n",
    "ELE17451 GRO73461 DAI22896 SNA99873 FRO86643 \n",
    "ELE17451 ELE37798 FRO86643 GRO56989 ELE23393 SNA11465 \n",
    "ELE17451 SNA69641 FRO86643 FRO78087 SNA11465 GRO39357 ELE28573 ELE11375 DAI54444 \n",
    "\n",
    "\n",
    "HW3.7. Shopping Cart Analysis\n",
    "Product Recommendations: The action or practice of selling additional products or services \n",
    "to existing customers is called cross-selling. Giving product recommendation is \n",
    "one of the examples of cross-selling that are frequently used by online retailers. \n",
    "One simple method to give product recommendations is to recommend products that are frequently\n",
    "browsed together by the customers.\n",
    "\n",
    "Suppose we want to recommend new products to the customer based on the products they\n",
    "have already browsed on the online website. Write a program using the A-priori algorithm\n",
    "to find products which are frequently browsed together. Fix the support to s = 100 \n",
    "(i.e. product sets need to occur together at least 100 times to be considered frequent) \n",
    "and find itemsets of size 2 and 3.\n",
    "\n",
    "Then extract association rules from these frequent items. \n",
    "\n",
    "A rule is of the form: \n",
    "\n",
    "(item1, item5) ⇒ item2.\n",
    "\n",
    "List the top 10 discovered rules in descreasing order of confidence in the following format\n",
    " \n",
    "(item1, item5) ⇒ item2, supportCount ,support, confidence\n",
    "\n",
    "HW3.8\n",
    "\n",
    "Benchmark your results using the pyFIM implementation of the Apriori algorithm\n",
    "(Apriori - Association Rule Induction / Frequent Item Set Mining implemented by Christian Borgelt). \n",
    "You can download pyFIM from here: \n",
    "\n",
    "http://www.borgelt.net/pyfim.html\n",
    "\n",
    "Comment on the results from both implementations (your Hadoop MapReduce of apriori versus pyFIM) \n",
    "in terms of results and execution times.\n",
    "\n",
    "\n",
    "HW3.8 (Conceptual Exercise)\n",
    "\n",
    "Suppose that you wished to perform the Apriori algorithm once again,\n",
    "though this time now with the goal of listing the top 5 rules with corresponding confidence scores \n",
    "in decreasing order of confidence score for itemsets of size 3 using Hadoop MapReduce.\n",
    "A rule is now of the form: \n",
    "\n",
    "(item1, item2) ⇒ item3 \n",
    "\n",
    "Recall that the Apriori algorithm is iterative for increasing itemset size,\n",
    "working off of the frequent itemsets of the previous size to explore \n",
    "ONLY the NECESSARY subset of a large combinatorial space. \n",
    "Describe how you might design a framework to perform this exercise.\n",
    "\n",
    "In particular, focus on the following:\n",
    "  — map-reduce steps required\n",
    "  - enumeration of item sets and filtering for frequent candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
